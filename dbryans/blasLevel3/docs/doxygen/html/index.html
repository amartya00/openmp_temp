<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>BLAS Level 3: BLAS (Basic Linear Algebra sub routines) level 3</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<table width=100%>
<tr>
  <td bgcolor="black" width="1"><a href="http://www.ti.com"><img border=0 src="tilogo.gif"></a></td>
  <td bgcolor="red"><img src="titagline.gif"></td>
</tr>
</table>
<!-- Generated by Doxygen 1.7.4 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">BLAS (Basic Linear Algebra sub routines) level 3 </div>  </div>
</div>
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="description"></a>
Description</h2>
<h3><a class="anchor" id="overview"></a>
Package overview</h3>
<p>The purpose of this package is to demonstrate Basic Linear Algebra routines on TI TMS320C6678. It provides optimized implementations of BLAS level 3 functions for single C66 core architecture. Based on the single core APIs, openMP can be used to distribute processing across the cores. The test package illustrates the openMP based thread distribution across all the eight cores available in C6678. The projects included in this package is designed to work with C6678 Evaluation module (EVM).</p>
<h3><a class="anchor" id="contents"></a>
Contents</h3>
<p>Below is a short description of the contents of the directories in this package. We assume that you have installed the BLAS level 3 files in INSTALL_DIR.</p>
<ul>
<li>INSTALL_DIR/docs: Doxygen documentation.</li>
<li>INSTALL_DIR/inc: Header files.</li>
<li>INSTALL_DIR/lib/C66/blas3libMCOmp: Precompiled library for multi-core APIs that uses openMP</li>
<li>INSTALL_DIR/lib/C66/blas3libSCOmp: Precompiled library for single core API (multi-core ready through openMP).</li>
<li>INSTALL_DIR/platformRepo: C6678 platform files used for project.</li>
<li>INSTALL_DIR/src/singleCore/dataMove: Different types of data re-arranagements needed by various modules.</li>
<li>INSTALL_DIR/src/singleCore/kernels: C66 optimized kernels used in the BLAS implementations.</li>
<li>INSTALL_DIR/src/singleCore/x&lt;blas3_function&gt;: Implementation of various single core BLAS level 3 functions.</li>
<li>INSTALL_DIR/src/multiCore/x&lt;blas3_function&gt;: Implementation of various multi core BLAS level 3 functions.</li>
<li>INSTALL_DIR/src/util: Utility functions for memory, cache and DMA.</li>
<li>INSTALL_DIR/test/ccsProj_C6678: CCS 5.2 project definitions.</li>
<li>INSTALL_DIR/test/params: Various parameter definitions used in test package.</li>
<li>INSTALL_DIR/test/src: Baseline test bench.</li>
<li>INSTALL_DIR/test/src/util: Various utilities used by test bench.</li>
<li>INSTALL_DIR/test/src/x&lt;blas3_function&gt;: various BLAS level 3 functiona test bench.</li>
<li>INSTALL_DIR/test/blas3_param_*.txt: defines parameter files to be used by test benches of various projects.</li>
</ul>
<h3><a class="anchor" id="Supported"></a>
BLAS Level 3 Functionalities</h3>
<table  border="1">
<tr>
<td>Level 3 BLAS </td><td>Types supported  </td></tr>
<tr>
<td>xGEMM </td><td>c, d, s, z  </td></tr>
<tr>
<td>xSYMM </td><td>c, d, s, z  </td></tr>
<tr>
<td>xHEMM </td><td>c, z  </td></tr>
<tr>
<td>xSYRK </td><td>c, d, s, z  </td></tr>
<tr>
<td>xHERK </td><td>c, z  </td></tr>
<tr>
<td>xSYR2K </td><td>c, d, s, z  </td></tr>
<tr>
<td>xHER2K </td><td>c, z  </td></tr>
<tr>
<td>xTRMM </td><td>c, d, s, z  </td></tr>
<tr>
<td>xTRSM </td><td>c, d, s, z  </td></tr>
</table>
<p>Both single-core and multi-core APIs are provided. The single core APIs can be distributed across multiple cores through OPENMP pragmas. The multi-core API uses a pre-defined distribution through openMP pragmas. The test bench reads a parameter file which contains the list of tests to be performed. Associated with the test is also another parameter file under the INSTALL_DIR/test/params directory that defines the particular parameters used in the test. A reference output for each test bench run has also been supplied at INSTALL_DIR/test/params/refResults.</p>
<h3><a class="anchor" id="API"></a>
Usage contraints</h3>
<p>The internal kernels compute <img class="formulaInl" alt="$m_{kernel}$" src="form_0.png"/> x <img class="formulaInl" alt="$n_{kernel}$" src="form_1.png"/> of the output (C) matrix at a time putting some contsraints on the sizes of the matrices. The values of <img class="formulaInl" alt="$m_{kernel}$" src="form_0.png"/> and <img class="formulaInl" alt="$n_{kernel}$" src="form_1.png"/> are dependent of data type and are tabulated below</p>
<table  border="1">
<tr>
<td>type </td><td><img class="formulaInl" alt="$m_{kernel}$" src="form_0.png"/> </td><td><img class="formulaInl" alt="$n_{kernel}$" src="form_1.png"/>  </td></tr>
<tr>
<td>C </td><td>2 </td><td>4  </td></tr>
<tr>
<td>D </td><td>4 </td><td>4  </td></tr>
<tr>
<td>S </td><td>4 </td><td>8  </td></tr>
<tr>
<td>Z </td><td>1 </td><td>1  </td></tr>
</table>
<p>The single core will produce correct output for any values of m and n. However, it will write its output in blocks of data size <img class="formulaInl" alt="$m_{kernel}$" src="form_0.png"/> x <img class="formulaInl" alt="$n_{kernel}$" src="form_1.png"/>, thereby modifying some extra values in memory unless the sizes are appropriately chosen. Some APIs also calculate the transpose of the desired matrix internally and writes it back in original form. In addition, to maintain cache coherency across cores, the APIs perform a cache write back after the output is computed. The APIs also invalidate any other memory that it uses to ensure cache coherency between calls. The APIs assume column first memory arrangement of data.</p>
<p>In multi-core application, the matrices are divided into blocks which are operated independently by different cores. The starting address of all the input/output matrix blocks should be aligned to cache line size. All the columns in the block will also need to be aligned with cache line size.</p>
<p>In order to guarantee safe operation by all cores, The block sizes should be made a multiple of cache line size of L2 memory (128 bytes).</p>
<p>Before any of the APIs are used, <a class="el" href="group__util.html#ga8638892aa3a8d9d027ce6b67206dd2d9" title="initilizes edma transfer for">edmaInit()</a> needs to be called to setup the DMA resource. This needs to be called only once before any of the APIs are called. <a class="el" href="group__util.html#ga5a240390bcbd5779092b01a77f28d844" title="initilizes closes and releases all edma channels for">edmaClose()</a> can be used to release the DMA resources. If the APIs are used as part of a larger program which uses other DMA resources, then DMA resources may need to be adjusted to avoid conflicts of usage.</p>
<p>For multi-core API, omp_set_num_threads() should be used to set the number of cores/threads to run.</p>
<h2><a class="anchor" id="build"></a>
Build Procedure</h2>
<h3><a class="anchor" id="tools"></a>
Tools needed</h3>
<ul>
<li>Code Composer Studio (CCS) 5.2 available at <a href="http://processors.wiki.ti.com/index.php/Download_CCS#Code_Composer_Studio_Version_5_Downloads">http://processors.wiki.ti.com/index.php/Download_CCS#Code_Composer_Studio_Version_5_Downloads</a></li>
<li>BIOS MCSDK 2.1.0.2 beta: available for selective engagement (you will be notified where to get it). The followings are useful documentation for use of BIOS MCSDK: <a href="http://processors.wiki.ti.com/index.php/BIOS_MCSDK_2.0_Getting_Started_Guide,">http://processors.wiki.ti.com/index.php/BIOS_MCSDK_2.0_Getting_Started_Guide,</a> <a href="http://processors.wiki.ti.com/index.php/BIOS_MCSDK_2.0_User_Guide">http://processors.wiki.ti.com/index.php/BIOS_MCSDK_2.0_User_Guide</a></li>
<li>Code Generation tool (CGT): version 7.4.0A12012 as distributed with MC SDK 2.1.0.1. Please ensure that the CGT is installed before importing the projects.</li>
</ul>
<p>The following components of the BIOS MCSDK are used with this project</p>
<ul>
<li>EDMA3 LLD: 2.11.05.02 (direct memory access controller driver)</li>
<li>PDK-6678: 1.1.0.2 (platform development kit)</li>
<li>IPC: 1.24.02.27 (inter processor communication)</li>
<li>OMP: 1.01.02.03 beta (opneMP runtime)</li>
</ul>
<h3><a class="anchor" id="tokens"></a>
Tokens used in the code:</h3>
<p>The following token pre-defines are used in the code. This can be used to turn on or off certain features in the code during compilation.</p>
<ul>
<li>PROFILE_CYCLES: To enable GFLOPS profiling.</li>
<li>DMA_COPYA: If defined, uses DMA to tranfer matrix A between DDR3 memory and internal memory. Otherwise, uses CPU memcpy.</li>
<li>DMA_COPYB: If defined, uses DMA to tranfer matrix B between DDR3 memory and internal memory. Otherwise, uses CPU memcpy.</li>
<li>VERIFICATION: If verification with a reference implementation is desired. Currently, the reference implementation is based on LIBFLAME from University of Texas available at <a href="http://z.cs.utexas.edu/wiki/flame.wiki/FrontPage/.">http://z.cs.utexas.edu/wiki/flame.wiki/FrontPage/.</a> This package has BLAS in C derived from Fortran to C conversion tool. There are several places the environment variable LIBFLAME_INSTALL_DIR need to be set. One is in the CCS itself. Go to Windows-&gt;Preferences-&gt;General-&gt;Workspace-&gt;Linked Resources. If the variable LIBFLAME_INSTALL_DIR is there, edit its value to point to your libflame installation. Otherwise, define the new variable LIBFLAME_INSTALL_DIR to point to your libflame installation. The other place is in the project itself. Go to project property-&gt;biuld-&gt;environemnt. Again, if the variable LIBFLAME_INSTALL_DIR is there, edit its value to point to your libflame installation. Otherwise, define the new variable LIBFLAME_INSTALL_DIR to point to your libflame installation. Note that the latter step needs to be done for each project that uses the reference code and each configuratin (debug and release) for the project. You may need to retstart CCS after these values are set to take these values into effect.</li>
</ul>
<h3><a class="anchor" id="projects"></a>
Pre-defined projects</h3>
<p>The following projects are pre-defined in the supplied codebase and can be imported in CCS using CCS-&gt;file-&gt;import-&gt;Code Composer Studio-&gt;Exisitng CCS/CCE Eclipse project.</p>
<ul>
<li>blas3libMCOmp: to create the libraries for multi-core core APIs; Will require the following single library to build an application</li>
<li>blas3libSCOmp: to create the libraries based on single core APIs (multi-core ready through openMP).</li>
<li>testBlasOmp: Used for multi-core implementation and verification using opneMP.</li>
<li>testBlasOmpNoReference: Used for multi-core core implementation and performance evaluation using openMP; does not use the reference code mentioned above.</li>
</ul>
<h3><a class="anchor" id="precompile"></a>
Using Pre-compiled libraries</h3>
<p>To use the pre-compile library in INSTALL_DIR/lib, follow the project definitions in one of the test projects. Specifically, one needs to</p>
<ul>
<li>add the INSTALL_DIR/lib/C66/blas3lib.cfg in the configuration file for the executable project. This file defines the SYSBIOS and memory configurations needed for the best performance. One can use the xdc.loadCapsule comand in configuration file as used in the test projects.</li>
<li>add this library for linking in the project.</li>
<li>add the edma libraries for linking in the project.</li>
</ul>
<p>Note that in release mode, the GFLOPS profiling and DMA data movements are turned on by default. They are not used in debug mode.</p>
<p>The configuration files associated with these projects also illustrate the internal memory usage of each core by the APIs.</p>
<p>The projects can be built through CCS. To run the code, launch the evm configuration (see MC-SDK documentation mentioned earlier).</p>
<ul>
<li>To run the single code, connect core #0 and load the binary on core #0 and run the code.</li>
<li>To run the eight core openMP code, connect core #0 through core #7 (you will find it useful to group these cores so you can connect and load in a single click) and load the binary on all the cores (core #0 trhough #7). cores #1 through #7 should be running and you need to start only core #0 manually to produce output.</li>
</ul>
<h3><a class="anchor" id="reset"></a>
Resetting the hardware in CCS</h3>
<p>Sometimes it is useful to reset the hardware specially for abnormal exits from the code. Follow the following procedure to reset the evm.</p>
<ul>
<li>reset each core: highlight each core (or group of cores); from CCS, use Run-&gt;reset-&gt;CPU reset</li>
<li>reset system: highlight core #0, from CCS, use Run-&gt;reset-&gt;system reset and then from CCS, use Script-&gt;EVMC6678L Init Functions-&gt;Global_Default_Setup</li>
</ul>
<p>You can now load the binary as above and rerun the code.</p>
<h2><a class="anchor" id="reference"></a>
References</h2>
<p>Some of the techniques used in this code base are described in the following references</p>
<p>1. Goto, K. and Van De Geijn, R., "Anatomy of High-Performfnace Matrix Multiplication," ACM Transactions on Mathematical Software, Vol. 34, No. 3, Article 12, May 2008.</p>
<p>2. Goto, K. and Van De Geijn, R., "High-Performance Implementation of the Level-3 BLAS," ACM Transactions on Mathematical Software, Vol. 35, No. 1, Article 4, July 2008. </p>
</div></div>
<hr size="1"><small>
Copyright  2012, Texas Instruments Incorporated</small>
</body>
</html>
